# .github/workflows/daily_scrape.yml
name: Daily Scrape & Update

on:
  schedule:
    - cron: '50 22 * * *'
    
  # 手動実行ボタン
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run scrape script
        env:
          GSPREAD_JSON: ${{ secrets.GSPREAD_JSON }}
          SHEET_ID:     ${{ secrets.SHEET_ID }}
          LOGIN_URL: ${{ secrets.LOGIN_URL }}
          LOGIN_USER: ${{ secrets.LOGIN_USER }}
          LOGIN_PASS: ${{ secrets.LOGIN_PASS }}
          LOGIN_SUCCESS_URL: ${{ secrets.LOGIN_SUCCESS_URL }}
          WEB_BASE: ${{ secrets.WEB_BASE }}
          VIBER_AUTH_TOKEN: ${{ secrets.VIBER_AUTH_TOKEN }}
          VIBER_USER_ID: ${{ secrets.VIBER_USER_ID }}

        run: |
          python scrape_and_update.py

      - name: Dump secret snippet
        run: |
          echo "----BEGIN PRIVATE_KEY SNIPPET----"
          echo "${{ secrets.GSPREAD_JSON }}" | head -n5
          echo "----END SNIPPET----"
